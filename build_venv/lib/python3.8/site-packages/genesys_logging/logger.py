"""Common logging framework"""

from datetime import datetime
import json
from logging import Logger as LoggerType
from logging import Formatter, getLogger, StreamHandler
from logging import DEBUG, INFO, WARNING, ERROR, CRITICAL
from os import environ
from typing import Any, Dict


class Logger:
    """Simplifies and optimizes logging setup for JSON formatted logs"""

    __slots__ = ('_name', 'logger', 'default_fields')

    # 1. Serves as a cache for loggers so that they may be used across invocations
    # 2. Allows for separate imports and instances in separate modules to use the same logger
    loggers: Dict[str, LoggerType] = {}
    default_fields_cache: Dict[str, Dict[str, Any]] = {}

    def __init__(
            self,
            name: str = 'MAIN',
            log_level: str = environ.get('LOG_LEVEL', 'info'),
            add_handler: bool = True,
            clear_formatters: bool = False
    ) -> None:
        """
        Fetches the logger, setting it up if not yet created for the current name
        :param name: The name for the current logger, defaults to 'MAIN'
        :param log_level: The initial log level to set, defaults to the LOG_LEVEL environment variable or 'info'
            if not present.
        :param add_handler: If True, adds a log handler with no formatter to the logger if it does not yet exist
        :param clear_formatters: If True, clears the formatter of all handlers in the log stack in order to ensure that
            the formatting done by this class is fully preserved. The formatting done by this class creates logs are
            more sumo friendly. This is primarily designed for use in AWS lambda, where AWS assigns default formatters
            to our logs that make them extremely difficult to parse in sumo. Note that this is a potentially
            destructive operation which could potentially clear formatters for third party libraries depending on how
            they are configured. If this functionality is needed, it is recommended to only run it once at initial
            logger creation and to run it as close to the entry point of your code as possible.
        """
        self._name = name
        if self._name not in self.__class__.loggers:
            self.__class__.loggers[self._name] = getLogger(self._name)
            self.__class__.default_fields_cache[self._name] = {}
        self.logger: LoggerType = self.__class__.loggers[self._name]
        self.set_level(level=log_level)
        if (not self.logger.hasHandlers()) and add_handler:
            handler = StreamHandler()
            handler.setLevel(level=log_level.upper())
            self.logger.addHandler(handler)
        if clear_formatters:
            current_logger = self.logger
            while current_logger:
                for handler in current_logger.handlers:
                    handler.setFormatter(Formatter())
                current_logger = current_logger.parent  # Is None if no parent is present, exiting the while loop

    @staticmethod
    def _check_reserved_keys(log_kwargs: Dict[str, Any]) -> None:
        """
        Runs an evaluation on a log or default fields to ensure that no reserved keys were used
        :param log_kwargs: The log kwargs or default field kwargs to evaluate
        """
        if 't' in log_kwargs:
            raise Exception('"t" is a reserved key for sumo timestamp parsing and cannot be manually provided')
        if 'level' in log_kwargs:
            raise Exception('"level" is automatically injected into the log and cannot be manually provided')

    def add_default_fields(self, **kwargs):
        """
        Adds default fields to use in logs
        :param kwargs: The fields to set
        :return: The instance itself for using this function in a context manager
        """
        self._check_reserved_keys(log_kwargs=kwargs)
        self.__class__.default_fields_cache[self._name].update(kwargs)
        return self

    def clear_default_fields(self) -> None:
        """Clears the default fields"""
        self.__class__.default_fields_cache[self._name] = {}

    def __enter__(self):
        """Allows using default fields in a context manager"""
        return self

    def __exit__(self, exc_type, exc_value, exc_tb) -> None:
        """Supports calling clear_default_fields on exit of a 'with' statement"""
        self.clear_default_fields()

    def _json_formatter(self, log_kwargs: Dict[str, Any], level: str) -> str:
        """
        Creates a specialized json format of the log for better sumo parsing
            * Adds the log to the default fields, overwriting where necessary
            * Injects the log level into the final log
            * Ensures a timestamp is always present in the log as the first key
        :param log_kwargs: The keyword arguments to transform into JSON for logging
        :param level: The level this message is being logged at
        :return: The finalized json log
        """
        self._check_reserved_keys(log_kwargs=log_kwargs)
        log_with_defaults = self.__class__.default_fields_cache[self._name].copy()
        log_with_defaults.update(log_kwargs)
        log_with_defaults['level'] = level
        return f'{{"t": "{datetime.utcnow().isoformat()[:-3]+"Z"}", {json.dumps(log_with_defaults)[1:]}\n'

    def debug(self, **kwargs) -> None:
        """
        Logs kwargs as JSON at the debug level
        :param kwargs: The keyword arguments to transform into JSON for logging
        """
        self.logger.debug(self._json_formatter(log_kwargs=kwargs, level='DEBUG'))

    def info(self, **kwargs) -> None:
        """
        Logs kwargs as JSON at the info level
        :param kwargs: The keyword arguments to transform into JSON for logging
        """
        self.logger.info(self._json_formatter(log_kwargs=kwargs, level='INFO'))

    def warning(self, **kwargs) -> None:
        """
        Logs kwargs as JSON at the warn level
        :param kwargs: The keyword arguments to transform into JSON for logging
        """
        self.logger.warning(self._json_formatter(log_kwargs=kwargs, level='WARNING'))

    def error(self, **kwargs) -> None:
        """
        Logs kwargs as JSON at the error level
        :param kwargs: The keyword arguments to transform into JSON for logging
        """
        self.logger.error(self._json_formatter(log_kwargs=kwargs, level='ERROR'))

    def critical(self, **kwargs) -> None:
        """
        Logs kwargs as JSON at the critical level
        :param kwargs: The keyword arguments to transform into JSON for logging
        """
        self.logger.critical(self._json_formatter(log_kwargs=kwargs, level='CRITICAL'))

    def set_level(self, level: str) -> None:
        """
        Sets the log level for the current logger
        :param level: The level to set the current logger to
        """
        level_var = f'_{level.lower()}'
        if hasattr(self, level_var):
            getattr(self, level_var)()
        else:
            raise Exception(f'Invalid level: {level}')

    def _debug(self) -> None:
        """Sets the level to debug for the active logger"""
        self.logger.setLevel(DEBUG)

    def _info(self) -> None:
        """Sets the level to info for the active logger"""
        self.logger.setLevel(INFO)

    def _warning(self) -> None:
        """Sets the level to warn for the active logger"""
        self.logger.setLevel(WARNING)

    def _error(self) -> None:
        """Sets the level to error for the active logger"""
        self.logger.setLevel(ERROR)

    def _critical(self) -> None:
        """Sets the level to critical for the active logger"""
        self.logger.setLevel(CRITICAL)
